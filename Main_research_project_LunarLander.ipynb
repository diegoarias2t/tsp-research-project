{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4438831",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59935980",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ce256",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall gym -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bac16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f60921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==1.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf722eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import stable_baselines\n",
    "stable_baselines.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82057e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall gym -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72190a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gym==0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52baa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import ml_monitor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines import DDPG, TD3\n",
    "from stable_baselines.ddpg.policies import LnMlpPolicy\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec, NormalActionNoise\n",
    "from stable_baselines.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3aad5f",
   "metadata": {},
   "source": [
    "## Gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLanderContinuous-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf338397",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae6681",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1099af2",
   "metadata": {},
   "source": [
    "### Callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf064e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, 'best_model')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        my_monitor.monitor(\"testing_switch\",0)\n",
    "        my_monitor.monitor(\"training_switch\",1)\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Num timesteps: {}\".format(self.num_timesteps))\n",
    "                    print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(self.best_mean_reward, mean_reward))\n",
    "                    my_monitor.monitor(\"num_timesteps\",self.num_timesteps)\n",
    "                    my_monitor.monitor(\"mean_reward\",mean_reward)\n",
    "                    \n",
    "            # New best model\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                self.best_mean_reward = mean_reward\n",
    "                my_monitor.monitor(\"best_mean_reward\",self.best_mean_reward)\n",
    "                # Saving best model\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Saving new best model to {}\".format(self.save_path))\n",
    "                self.model.save(self.save_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f7df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log dir\n",
    "log_dir = \"machine-learning/logs/\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e43e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the environment\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc099ba",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82009773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some param noise for exploration\n",
    "param_noise = AdaptiveParamNoiseSpec(initial_stddev=0.1, desired_action_stddev=0.1)\n",
    "# Create the callback: check every 1000 steps\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_monitor = ml_monitor.Monitor()\n",
    "my_monitor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21bd017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Because we use parameter noise, we should use a MlpPolicy with layer normalization\n",
    "model = DDPG(LnMlpPolicy, env, param_noise=param_noise, verbose=False)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(2e6), callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e62603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"machine-learning/models/LunarLander2e6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82554fc",
   "metadata": {},
   "source": [
    "## Testing phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6756105",
   "metadata": {},
   "source": [
    "### Fast import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cac80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gym==0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31190981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darias/.local/lib/python3.6/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ml_monitor\n",
    "\n",
    "from stable_baselines import DDPG, TD3\n",
    "from stable_baselines.ddpg.policies import LnMlpPolicy\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec, NormalActionNoise\n",
    "from stable_baselines.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d894e",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ba807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afb180b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:332: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/policies.py:134: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:459: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:459: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:132: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:412: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:444: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:720: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:432: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:452: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "model = DDPG.load(\"machine-learning/models/LunarLander1e6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc7473",
   "metadata": {},
   "source": [
    "### Agent environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b93cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 02:59:59,252 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:00,254 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:01,255 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:02,257 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    }
   ],
   "source": [
    "my_monitor = ml_monitor.Monitor()\n",
    "my_monitor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f894f4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:03,258 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:04,260 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:05,261 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:243.22222832228906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:06,266 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:07,267 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:08,268 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:09,270 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:10,271 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:11,272 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2 Score:284.4380653959041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:12,274 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:13,275 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:14,276 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:15,278 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:16,279 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:3 Score:269.45045757684613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:17,280 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:18,281 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:19,283 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:20,284 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:21,285 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:22,286 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:4 Score:270.76147577677085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:23,288 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:24,289 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:25,290 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:26,292 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:27,294 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:28,295 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:29,297 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:5 Score:299.71061106304506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:30,298 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:31,299 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:32,301 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:33,302 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:34,304 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:35,305 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:36,306 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:37,308 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:38,310 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:6 Score:255.81609836806572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:39,312 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:40,313 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:41,315 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:42,316 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:43,317 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:44,319 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:45,320 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:46,321 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:47,323 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:7 Score:248.51497712043536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:00:48,324 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:49,325 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:50,328 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:51,331 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:52,332 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:53,333 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:54,335 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:55,336 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:56,338 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:57,339 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:58,341 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:00:59,342 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:00,344 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:01,345 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:02,347 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:03,348 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:04,350 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:05,351 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:8 Score:231.8507628430394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:01:06,353 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:07,354 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:08,355 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:09,357 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:10,358 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:11,360 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:12,361 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:9 Score:312.1579912286416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:01:13,362 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:14,363 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:15,365 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:16,366 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:17,368 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:18,369 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:10 Score:281.49239675525666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:01:19,370 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:20,372 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:21,373 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:22,375 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:23,376 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:24,378 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:11 Score:310.2683371816771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:01:25,379 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:26,381 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:27,382 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:28,384 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:29,385 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:30,387 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:31,388 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:32,389 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:33,390 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:34,392 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:35,393 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:36,394 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:37,396 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:38,398 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:39,399 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:40,400 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:12 Score:237.591789503752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:01:41,402 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:42,403 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:43,404 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:44,405 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:45,407 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:46,408 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:13 Score:248.2586146024515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:01:47,410 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:48,412 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:49,413 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:50,415 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:51,416 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:52,417 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:53,418 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:14 Score:264.3035487267238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:01:54,420 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:55,421 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:56,422 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:57,424 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:58,425 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:01:59,427 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:00,429 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:15 Score:314.8743987539766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:01,430 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:02,432 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:03,434 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:04,435 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:05,436 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:16 Score:297.5529312120091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:06,437 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:07,439 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:08,440 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:09,442 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:10,443 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:11,444 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:17 Score:290.46594527359235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:12,447 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:13,448 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:14,450 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:15,451 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:16,453 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:17,454 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:18,455 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:19,457 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:20,459 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:18 Score:238.24770511672398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:21,460 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:22,462 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:23,463 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:24,465 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:25,466 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:19 Score:264.4517436973086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:26,468 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:27,469 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:28,470 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:29,472 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:30,474 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:31,476 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:32,478 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:33,479 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:20 Score:230.2102578874133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:34,481 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:35,482 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:36,484 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:37,485 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:38,487 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:39,488 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:40,490 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:21 Score:288.196863239339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:41,491 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:42,493 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:43,494 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:44,496 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:45,497 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:46,499 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:47,500 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:22 Score:309.200090824962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:48,502 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:49,503 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:50,505 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:51,506 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:52,508 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:53,509 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:54,511 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:23 Score:275.4594219202147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:02:55,512 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:56,514 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:57,515 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:58,517 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:02:59,518 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:24 Score:309.14567561651455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:00,520 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:01,521 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:02,522 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:03,523 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:04,524 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:05,526 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:06,528 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:25 Score:278.1971307130223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:07,530 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:08,531 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:09,532 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:10,535 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:11,536 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:12,537 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:13,539 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:26 Score:260.29533735439946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:14,540 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:15,542 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:16,543 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:17,545 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:18,546 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:19,548 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:20,549 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:21,550 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:22,552 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:23,553 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:24,554 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:25,556 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:26,557 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:27,559 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:28,561 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:29,562 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:27 Score:187.28406819478596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:30,563 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:31,565 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:32,566 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:33,568 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:34,569 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:35,571 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:36,572 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:28 Score:301.9263523937034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:37,573 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:38,575 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:39,576 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:40,578 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:41,579 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:42,581 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:29 Score:309.1472381337283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:43,582 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:44,584 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:45,586 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:46,587 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:47,588 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:48,590 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:30 Score:311.5433244558641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:49,591 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:50,592 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:51,594 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:52,596 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:53,597 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:31 Score:279.3135723342149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:03:54,599 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:55,601 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:56,602 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:57,603 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:58,605 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:03:59,607 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:32 Score:245.11785097112045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:00,608 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:01,609 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:02,610 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:03,612 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:04,615 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:05,617 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:33 Score:294.003687223562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:06,625 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:07,629 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:08,639 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:09,641 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:10,643 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:11,655 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:34 Score:274.0507859352322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:12,656 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:13,659 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:14,662 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:15,667 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:16,668 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:17,672 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:35 Score:254.50694612301442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:18,673 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:19,675 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:20,676 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:21,679 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:22,680 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:23,691 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:24,694 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:25,697 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:36 Score:256.64917824916057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:26,704 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:27,706 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:28,709 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:29,710 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:30,719 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:31,720 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:37 Score:302.20504756032415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:32,722 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:33,724 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:34,726 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:35,731 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:36,733 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:37,737 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:38 Score:253.09364190247044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:38,740 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:39,741 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:40,742 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:41,744 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:42,755 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:43,760 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:39 Score:311.01632133839473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:44,762 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:45,763 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:46,764 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:47,766 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:48,768 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:49,770 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:40 Score:296.11561345171947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:50,771 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:51,772 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:52,774 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:53,775 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:54,782 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:55,784 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:56,786 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:57,787 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:41 Score:228.79874050669557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:04:58,788 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:04:59,790 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:00,792 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:01,794 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:02,799 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:42 Score:281.3590979208494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:03,811 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:04,814 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:05,816 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:06,820 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:07,821 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:08,823 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:43 Score:259.80921474737596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:09,825 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:10,826 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:11,828 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:12,830 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:13,833 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:14,840 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:44 Score:285.55746830836904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:15,847 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:16,848 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:17,850 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:18,851 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:19,852 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:20,853 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:45 Score:320.27607302863237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:21,855 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:22,856 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:23,857 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:24,859 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:25,860 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:26,865 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:46 Score:248.70728412559228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:27,866 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:28,868 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:29,869 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:30,871 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:31,872 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:32,874 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:47 Score:267.60667083214565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:33,875 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:34,877 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:35,878 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:36,880 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:37,882 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:38,885 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:48 Score:279.5943348310151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:39,886 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:40,888 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:41,889 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:42,890 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:43,891 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:49 Score:280.25816364599683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:44,893 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:45,894 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:46,895 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:47,896 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:48,898 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:49,899 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:50 Score:262.69192385664866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:50,902 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:51,903 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:52,904 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:53,905 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:54,907 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:55,908 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:51 Score:254.73084658148684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:05:56,909 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:57,910 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:58,912 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:05:59,913 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:00,915 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:01,916 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:02,917 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:03,918 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:04,919 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:52 Score:244.21218123008975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:06:05,921 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:06,922 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:07,924 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:08,925 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:09,926 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:10,927 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:53 Score:291.40978541656364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:06:11,929 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:12,931 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:13,933 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:14,935 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:15,936 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:16,937 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:54 Score:297.9402625639388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:06:17,939 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:18,940 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:19,941 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:20,943 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:21,944 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:22,946 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:55 Score:291.3212001633367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:06:23,948 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:24,949 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:25,950 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:26,952 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:27,953 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:28,955 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:29,957 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:30,958 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:31,959 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:32,961 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:33,963 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:34,965 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:56 Score:221.66772997964983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:06:35,966 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:36,967 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:37,969 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:38,970 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:39,972 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:40,973 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:41,975 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:42,976 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:43,977 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:44,978 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:45,980 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:46,982 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:47,983 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:48,985 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:49,986 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:50,988 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:51,989 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:52,990 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:53,991 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:57 Score:246.18907789981972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:06:54,993 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:55,994 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:56,995 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:57,997 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:06:58,998 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:58 Score:261.2301345133078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:00,000 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:01,002 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:02,003 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:03,004 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:04,005 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:05,007 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:06,008 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:07,009 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:59 Score:248.67797907112055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:08,011 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:09,012 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:10,013 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:11,015 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:12,016 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:13,018 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:14,019 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:15,020 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:60 Score:303.81374045703615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:16,022 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:17,023 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:18,024 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:19,025 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:20,027 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:21,028 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:22,030 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:23,033 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:61 Score:266.0646310461841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:24,034 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:25,035 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:26,036 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:27,038 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:28,039 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:29,040 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:62 Score:270.74588868974354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:30,041 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:31,043 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:32,044 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:33,047 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:34,048 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:35,050 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:63 Score:282.7901390711934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:36,051 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:37,053 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:38,054 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:39,056 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:40,057 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:64 Score:284.13390836482694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:41,058 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:42,059 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:43,061 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:44,062 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:45,064 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:46,067 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:65 Score:273.78701174697284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:07:47,071 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:48,072 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:49,073 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:50,074 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:51,076 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:52,077 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:53,078 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:54,080 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:55,081 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:56,083 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:57,084 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:58,085 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:07:59,086 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:00,088 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:01,089 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:02,090 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:03,091 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:04,093 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:05,094 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:66 Score:125.20119199908092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:06,095 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:07,097 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:08,098 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:09,100 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:10,101 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:11,102 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:12,104 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:67 Score:309.6804497481183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:13,105 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:14,106 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:15,107 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:16,108 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:17,110 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:18,111 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:68 Score:271.0714633493092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:19,113 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:20,113 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:21,115 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:22,116 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:23,117 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:24,119 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:69 Score:302.23668249054344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:25,120 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:26,121 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:27,122 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:28,124 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:29,125 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:30,127 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:70 Score:281.1943645083069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:31,128 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:32,129 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:33,131 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:34,132 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:35,134 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:36,135 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:71 Score:228.42508429469467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:37,137 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:38,138 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:39,139 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:40,140 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:41,142 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:42,143 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:43,145 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:72 Score:273.6382844040108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:44,146 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:45,147 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:46,149 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:47,150 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:48,151 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:49,153 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:73 Score:290.19329246684134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:50,155 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:51,156 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:52,157 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:53,158 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:54,160 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:55,161 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:56,162 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:74 Score:312.2243014556792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:08:57,164 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:58,165 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:08:59,166 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:00,169 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:01,170 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:75 Score:264.71203083083464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:02,172 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:03,173 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:04,175 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:05,176 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:06,177 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:07,179 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:08,180 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:76 Score:320.3952570786364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:09,182 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:10,184 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:11,185 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:12,186 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:13,188 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:14,189 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:77 Score:277.13764259112054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:15,190 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:16,192 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:17,193 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:18,195 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:19,196 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:20,197 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:21,198 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:22,199 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:23,202 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:78 Score:296.0309849423461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:24,203 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:25,205 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:26,206 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:27,207 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:28,208 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:29,210 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:79 Score:283.4184202787967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:30,211 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:31,212 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:32,214 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:33,215 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:34,217 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:35,218 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:36,220 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:37,221 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:38,222 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:39,223 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:40,225 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:41,226 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:80 Score:258.7309253459796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:42,227 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:43,228 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:44,230 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:45,231 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:46,233 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:47,234 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:81 Score:304.69115143250815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:48,236 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:49,237 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:50,238 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:51,240 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:52,241 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:53,242 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:82 Score:279.17031449155866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:09:54,243 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:55,245 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:56,247 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:57,248 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:58,249 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:09:59,251 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:00,253 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:01,255 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:83 Score:297.20287505559884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:02,257 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:03,258 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:04,259 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:05,261 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:06,262 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:07,264 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:84 Score:316.53641272212775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:08,265 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:09,267 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:10,268 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:11,269 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:12,271 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:13,272 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:85 Score:280.53751656608694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:14,274 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:15,275 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:16,276 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:17,278 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:18,280 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:19,281 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:86 Score:264.95356559439017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:20,283 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:21,285 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:22,286 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:23,287 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:24,289 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:25,290 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:87 Score:289.3601809411002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:26,291 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:27,293 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:28,294 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:29,295 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:30,296 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:31,297 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:88 Score:294.06391679462934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:32,298 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:33,300 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:34,302 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:35,303 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:36,304 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:89 Score:269.0138593439922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:37,306 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:38,307 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:39,308 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:40,310 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:41,311 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:42,313 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:90 Score:284.5213560358775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:43,314 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:44,315 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:45,317 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:46,318 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:47,320 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:91 Score:252.62424402806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:48,321 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:49,323 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:50,324 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:51,325 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:52,327 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:53,328 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:54,329 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:92 Score:308.08104515031937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:10:55,331 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:56,332 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:57,334 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:58,335 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:10:59,336 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:00,338 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:01,339 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:02,340 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:03,342 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:04,343 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:05,344 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:06,345 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:07,347 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:08,349 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:93 Score:255.92671649069678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:09,350 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:10,352 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:11,353 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:12,354 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:13,356 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:94 Score:281.23836638228914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:14,357 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:15,358 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:16,360 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:17,361 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:18,362 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:19,363 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:95 Score:246.6738285862518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:20,364 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:21,366 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:22,367 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:23,369 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:24,370 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:25,372 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:96 Score:271.93559608994815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:26,373 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:27,374 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:28,375 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:29,377 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:30,378 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:31,379 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:97 Score:271.1430649912064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:32,381 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:33,382 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:34,384 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:35,385 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:36,387 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:37,389 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:98 Score:281.3841366485625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:38,390 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:39,391 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:40,393 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:41,394 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:42,395 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:43,396 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:99 Score:278.15242125962527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:44,398 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:45,399 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:46,400 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:47,401 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:48,403 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:100 Score:254.64923403693524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:11:49,404 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:50,405 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:51,406 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:52,408 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:53,409 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:54,410 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:55,411 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:56,413 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:57,414 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:58,416 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:11:59,417 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:00,418 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:01,420 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:02,421 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:03,423 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:04,424 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:05,426 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:06,427 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:07,428 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:08,430 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:09,431 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:10,433 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:11,434 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:12,436 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:13,437 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:14,438 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:15,440 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:16,442 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:17,443 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:18,444 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:19,446 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:20,447 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:21,449 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:22,450 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:23,451 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:24,453 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:25,455 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:26,456 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:27,457 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:28,458 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:29,460 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:30,461 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:31,462 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:32,464 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:33,465 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:34,466 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:35,468 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:36,469 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:37,470 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:38,472 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:39,473 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:40,475 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:41,476 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:42,477 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:43,479 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:44,480 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:45,481 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:46,483 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:47,484 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:48,485 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:49,487 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:50,488 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:51,489 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:52,490 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:53,492 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:54,493 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:55,495 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:56,496 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:57,497 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:58,499 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:12:59,501 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:00,502 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:01,504 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:02,506 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:03,507 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:04,508 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:05,509 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:06,511 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:07,513 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:08,514 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:09,516 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:10,517 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:11,519 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:12,520 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:13,521 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:14,522 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:15,525 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 03:13:16,526 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:17,527 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:18,528 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:19,530 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:20,532 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:21,533 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:22,534 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:23,536 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:24,537 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:25,539 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:26,541 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:27,542 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:28,543 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:29,544 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:30,545 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:31,547 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:32,548 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:33,549 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-02-10 03:13:34,551 [4759] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    }
   ],
   "source": [
    "my_monitor.monitor(\"testing_switch\",1)\n",
    "my_monitor.monitor(\"training_switch\",0)\n",
    "episodes = 100\n",
    "for episodes in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    my_monitor.monitor(\"testing_episodes\",episodes)\n",
    "    my_monitor.monitor(\"testing_score\",score)\n",
    "    print('Episode:{} Score:{}'.format(episodes, score))\n",
    "    time.sleep(3)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c99a05",
   "metadata": {},
   "source": [
    "## Ploting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61026471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import results_plotter\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results([log_dir], 1e5, results_plotter.X_TIMESTEPS, \"DDPG LunarLander\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(values, window):\n",
    "    \"\"\"\n",
    "    Smooth values by doing a moving average\n",
    "    :param values: (numpy array)\n",
    "    :param window: (int)\n",
    "    :return: (numpy array)\n",
    "    \"\"\"\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, 'valid')\n",
    "\n",
    "\n",
    "def plot_results(log_folder, title='Learning Curve'):\n",
    "    \"\"\"\n",
    "    plot the results\n",
    "\n",
    "    :param log_folder: (str) the save location of the results to plot\n",
    "    :param title: (str) the title of the task to plot\n",
    "    \"\"\"\n",
    "    x, y = ts2xy(load_results(log_folder), 'timesteps')\n",
    "    y = moving_average(y, window=50)\n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y):]\n",
    "\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Number of Timesteps')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.title(title + \" Smoothed\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66a8b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_results(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a451a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
