{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4438831",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042c852",
   "metadata": {},
   "source": [
    "### RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59935980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ -------------------\n",
      "absl-py                  0.15.0\n",
      "ale-py                   0.7.1\n",
      "apturl                   0.5.2\n",
      "argon2-cffi              21.3.0\n",
      "argon2-cffi-bindings     21.2.0\n",
      "asn1crypto               0.24.0\n",
      "astunparse               1.6.3\n",
      "async-generator          1.10\n",
      "attrs                    21.4.0\n",
      "backcall                 0.2.0\n",
      "bleach                   4.1.0\n",
      "Box2D                    2.3.10\n",
      "Box2D-kengz              2.3.3\n",
      "Brlapi                   0.6.6\n",
      "cached-property          1.5.2\n",
      "cachetools               4.2.4\n",
      "certifi                  2021.10.8\n",
      "cffi                     1.15.0\n",
      "chardet                  3.0.4\n",
      "charset-normalizer       2.0.10\n",
      "clang                    5.0\n",
      "click                    6.7\n",
      "cloudpickle              2.0.0\n",
      "colorama                 0.3.7\n",
      "command-not-found        0.3\n",
      "cryptography             2.1.4\n",
      "cupshelpers              1.0\n",
      "cycler                   0.11.0\n",
      "daiquiri                 1.6.1\n",
      "dataclasses              0.8\n",
      "decorator                5.1.1\n",
      "defer                    1.0.6\n",
      "defusedxml               0.7.1\n",
      "distlib                  0.3.4\n",
      "distro-info              0.18ubuntu0.18.04.1\n",
      "entrypoints              0.3\n",
      "filelock                 3.4.1\n",
      "flatbuffers              1.12\n",
      "gast                     0.4.0\n",
      "google-api-core          2.3.2\n",
      "google-api-python-client 2.34.0\n",
      "google-auth              1.35.0\n",
      "google-auth-httplib2     0.1.0\n",
      "google-auth-oauthlib     0.4.6\n",
      "google-pasta             0.2.0\n",
      "googleapis-common-protos 1.54.0\n",
      "GPUtil                   1.4.0\n",
      "grpcio                   1.43.0\n",
      "gym                      0.21.0\n",
      "h5py                     3.1.0\n",
      "httplib2                 0.20.2\n",
      "idna                     3.3\n",
      "importlib-metadata       4.8.3\n",
      "importlib-resources      5.4.0\n",
      "ipykernel                5.5.6\n",
      "ipython                  7.16.2\n",
      "ipython-genutils         0.2.0\n",
      "ipywidgets               7.6.5\n",
      "jedi                     0.17.2\n",
      "Jinja2                   3.0.3\n",
      "joblib                   1.1.0\n",
      "jsonschema               3.2.0\n",
      "jupyter                  1.0.0\n",
      "jupyter-client           7.1.0\n",
      "jupyter-console          6.4.0\n",
      "jupyter-core             4.9.1\n",
      "jupyterlab-pygments      0.1.2\n",
      "jupyterlab-widgets       1.0.2\n",
      "keras                    2.6.0\n",
      "Keras-Preprocessing      1.1.2\n",
      "keyring                  10.6.0\n",
      "keyrings.alt             3.0\n",
      "kiwisolver               1.3.1\n",
      "language-selector        0.1\n",
      "launchpadlib             1.10.6\n",
      "lazr.restfulclient       0.13.5\n",
      "lazr.uri                 1.0.3\n",
      "louis                    3.5.0\n",
      "macaroonbakery           1.1.3\n",
      "Mako                     1.0.7\n",
      "Markdown                 3.3.6\n",
      "MarkupSafe               2.0.1\n",
      "matplotlib               3.3.4\n",
      "mistune                  0.8.4\n",
      "ml-monitor               0.1.0\n",
      "mpi4py                   3.1.3\n",
      "nbclient                 0.5.9\n",
      "nbconvert                6.0.7\n",
      "nbformat                 5.1.3\n",
      "nest-asyncio             1.5.4\n",
      "netifaces                0.10.4\n",
      "notebook                 6.4.6\n",
      "numpy                    1.19.5\n",
      "oauth                    1.0.1\n",
      "oauth2client             4.1.3\n",
      "oauthlib                 3.1.1\n",
      "olefile                  0.45.1\n",
      "opencv-python            4.5.5.62\n",
      "opt-einsum               3.3.0\n",
      "packaging                21.3\n",
      "pandas                   1.1.5\n",
      "pandocfilters            1.5.0\n",
      "parso                    0.7.1\n",
      "pexpect                  4.2.1\n",
      "pickleshare              0.7.5\n",
      "Pillow                   8.4.0\n",
      "pip                      21.3.1\n",
      "platformdirs             2.4.0\n",
      "prometheus-client        0.12.0\n",
      "prompt-toolkit           3.0.24\n",
      "protobuf                 3.19.1\n",
      "psutil                   5.9.0\n",
      "ptyprocess               0.7.0\n",
      "pyasn1                   0.4.8\n",
      "pyasn1-modules           0.2.8\n",
      "pycairo                  1.16.2\n",
      "pycparser                2.21\n",
      "pycrypto                 2.6.1\n",
      "pycups                   1.9.73\n",
      "PyDrive                  1.3.1\n",
      "pyglet                   1.5.21\n",
      "Pygments                 2.11.2\n",
      "PyGObject                3.26.1\n",
      "pymacaroons              0.13.0\n",
      "PyNaCl                   1.1.2\n",
      "pyparsing                3.0.6\n",
      "pyRFC3339                1.0\n",
      "pyrsistent               0.18.0\n",
      "python-apt               1.6.5+ubuntu0.7\n",
      "python-dateutil          2.8.2\n",
      "python-debian            0.1.32\n",
      "pytz                     2018.3\n",
      "pyxdg                    0.25\n",
      "PyYAML                   5.4.1\n",
      "pyzmq                    22.3.0\n",
      "qtconsole                5.2.2\n",
      "QtPy                     2.0.0\n",
      "reportlab                3.4.0\n",
      "requests                 2.27.1\n",
      "requests-oauthlib        1.3.0\n",
      "requests-unixsocket      0.1.5\n",
      "rsa                      4.8\n",
      "scipy                    1.5.4\n",
      "seaborn                  0.11.2\n",
      "SecretStorage            2.3.1\n",
      "Send2Trash               1.8.0\n",
      "setuptools               59.6.0\n",
      "simplejson               3.13.2\n",
      "six                      1.15.0\n",
      "stable-baselines         2.10.2\n",
      "system-service           0.3\n",
      "systemd-python           234\n",
      "tensorboard              2.6.0\n",
      "tensorboard-data-server  0.6.1\n",
      "tensorboard-plugin-wit   1.8.1\n",
      "tensorflow               2.6.2\n",
      "tensorflow-estimator     2.6.0\n",
      "termcolor                1.1.0\n",
      "terminado                0.12.1\n",
      "testpath                 0.5.0\n",
      "tornado                  6.1\n",
      "traitlets                4.3.3\n",
      "typing-extensions        3.7.4.3\n",
      "ubuntu-advantage-tools   27.2\n",
      "ubuntu-drivers-common    0.0.0\n",
      "ufw                      0.36\n",
      "unattended-upgrades      0.1\n",
      "uritemplate              4.1.1\n",
      "urllib3                  1.26.8\n",
      "usb-creator              0.3.3\n",
      "virtualenv               20.13.0\n",
      "wadllib                  1.3.2\n",
      "wcwidth                  0.2.5\n",
      "webencodings             0.5.1\n",
      "Werkzeug                 2.0.2\n",
      "wheel                    0.37.1\n",
      "widgetsnbextension       3.5.2\n",
      "wrapt                    1.12.1\n",
      "xkit                     0.0.0\n",
      "zipp                     3.6.0\n",
      "zope.interface           4.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0fe559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf722eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'contextlib' has no attribute 'nullcontext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-af2d36a0b442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/stable_baselines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mA2C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macktr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACKTR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/stable_baselines/a2c/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mA2C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/stable_baselines/a2c/a2c.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Hook to load plugins from entry points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0m_load_env_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload_env_plugins\u001b[0;34m(entry_point)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__internal__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplugin_internal_whitelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 logger.warn(\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'contextlib' has no attribute 'nullcontext'"
     ]
    }
   ],
   "source": [
    "import stable_baselines\n",
    "stable_baselines.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52baa8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'contextlib' has no attribute 'nullcontext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-22e74ec51415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Hook to load plugins from entry points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0m_load_env_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload_env_plugins\u001b[0;34m(entry_point)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__internal__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplugin_internal_whitelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 logger.warn(\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'contextlib' has no attribute 'nullcontext'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines import DDPG, TD3\n",
    "from stable_baselines.ddpg.policies import LnMlpPolicy\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec, NormalActionNoise\n",
    "from stable_baselines.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea905ef0",
   "metadata": {},
   "source": [
    "### ML Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b85d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets import the ml_monotor library\n",
    "import ml_monitor\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1099af2",
   "metadata": {},
   "source": [
    "### Callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a006d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 14:39:50,886 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    }
   ],
   "source": [
    "my_monitor = ml_monitor.Monitor()\n",
    "my_monitor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf064e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, 'best_model')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Num timesteps: {}\".format(self.num_timesteps))\n",
    "                    print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(self.best_mean_reward, mean_reward))\n",
    "                    my_monitor.monitor(\"num_timesteps\",self.num_timesteps)\n",
    "                    \n",
    "                    \n",
    "            # New best model, you could save the agent here\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                self.best_mean_reward = mean_reward\n",
    "                # Example for saving best model\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Saving new best model to {}\".format(self.save_path))\n",
    "                self.model.save(self.save_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f7df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log dir\n",
    "log_dir = \"machine-learning/logs/\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e9e43e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gym.envs.box2d' has no attribute 'LunarLanderContinuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-48d390bda1f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create and wrap the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLanderContinuous-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Logs will be saved in log_dir/monitor.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 )\n\u001b[1;32m    155\u001b[0m             )\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeLimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_enforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_enforcing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderEnforcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 )\n\u001b[1;32m     71\u001b[0m             )\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 2016-10-31: We're experimentally expanding the environment ID format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;31m# to include an optional username.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0menv_id_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^(?:[\\w:-]+\\/)?([\\w:.-]+)-v(\\d+)$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gym.envs.box2d' has no attribute 'LunarLanderContinuous'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 14:39:55,888 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:00,889 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:05,891 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:10,892 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:15,894 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:20,895 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:25,896 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:30,898 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:35,899 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:40,901 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:45,902 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:50,903 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:40:55,905 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:41:00,907 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:41:05,908 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:41:10,909 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:41:15,911 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:41:20,912 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2022-01-26 14:41:25,914 [39636] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    }
   ],
   "source": [
    "# Create and wrap the environment\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc099ba",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82009773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some param noise for exploration\n",
    "param_noise = AdaptiveParamNoiseSpec(initial_stddev=0.1, desired_action_stddev=0.1)\n",
    "# Create the callback: check every 1000 steps\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21bd017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:34:26,802 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 1000\n",
      "Best mean reward: -189.41 - Last mean reward per episode: -186.96\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 2000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -192.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:34:31,803 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 3000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -210.06\n",
      "Num timesteps: 4000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -212.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:34:36,805 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 5000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -212.33\n",
      "Num timesteps: 6000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -213.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:34:41,806 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 7000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -211.86\n",
      "Num timesteps: 8000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -208.39\n",
      "Num timesteps: 9000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -209.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:34:46,808 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 10000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -206.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:34:51,809 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 11000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -194.40\n",
      "Num timesteps: 12000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -187.62\n",
      "Num timesteps: 13000\n",
      "Best mean reward: -186.96 - Last mean reward per episode: -177.41\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:34:56,813 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 14000\n",
      "Best mean reward: -177.41 - Last mean reward per episode: -164.66\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 15000\n",
      "Best mean reward: -164.66 - Last mean reward per episode: -147.72\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:01,816 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 16000\n",
      "Best mean reward: -147.72 - Last mean reward per episode: -147.01\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:06,818 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 17000\n",
      "Best mean reward: -147.01 - Last mean reward per episode: -145.23\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 18000\n",
      "Best mean reward: -145.23 - Last mean reward per episode: -142.46\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 19000\n",
      "Best mean reward: -142.46 - Last mean reward per episode: -139.75\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:11,821 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 20000\n",
      "Best mean reward: -139.75 - Last mean reward per episode: -141.22\n",
      "Num timesteps: 21000\n",
      "Best mean reward: -139.75 - Last mean reward per episode: -141.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:16,822 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 22000\n",
      "Best mean reward: -139.75 - Last mean reward per episode: -140.62\n",
      "Num timesteps: 23000\n",
      "Best mean reward: -139.75 - Last mean reward per episode: -139.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:21,824 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 24000\n",
      "Best mean reward: -139.75 - Last mean reward per episode: -138.96\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 25000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -140.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:26,826 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 26000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -140.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:31,829 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 27000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -141.95\n",
      "Num timesteps: 28000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -144.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:36,832 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 29000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -144.75\n",
      "Num timesteps: 30000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -150.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:41,837 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 31000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -151.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:46,841 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 32000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -151.93\n",
      "Num timesteps: 33000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -153.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:51,848 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 34000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -154.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:35:56,849 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 35000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -155.89\n",
      "Num timesteps: 36000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -155.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:01,851 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 37000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -154.34\n",
      "Num timesteps: 38000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -153.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:06,852 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 39000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -153.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:11,857 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 40000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -153.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:16,863 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 41000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -152.65\n",
      "Num timesteps: 42000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -152.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:21,868 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 43000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -151.69\n",
      "Num timesteps: 44000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -154.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:26,875 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 45000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -151.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:31,876 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 46000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -150.69\n",
      "Num timesteps: 47000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -149.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:36,878 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 48000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -148.47\n",
      "Num timesteps: 49000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -147.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:41,881 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 50000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -146.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:46,897 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 51000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -146.66\n",
      "Num timesteps: 52000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -150.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:51,899 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 53000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -151.18\n",
      "Num timesteps: 54000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -151.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:36:56,904 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 55000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -153.06\n",
      "Num timesteps: 56000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -154.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:01,908 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 57000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -156.30\n",
      "Num timesteps: 58000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -159.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:06,910 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 59000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -162.83\n",
      "Num timesteps: 60000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -165.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:11,912 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 61000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -165.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:16,914 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 62000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -163.86\n",
      "Num timesteps: 63000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -164.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:21,915 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 64000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -164.03\n",
      "Num timesteps: 65000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -163.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:26,916 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 66000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -163.85\n",
      "Num timesteps: 67000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -162.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:31,918 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 68000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -165.88\n",
      "Num timesteps: 69000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -166.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:36,920 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 70000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -166.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:41,922 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 71000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -166.42\n",
      "Num timesteps: 72000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -165.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:46,923 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 73000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -166.62\n",
      "Num timesteps: 74000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -165.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:51,930 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 75000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -164.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:37:56,937 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 76000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -163.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:01,942 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 77000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -162.76\n",
      "Num timesteps: 78000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -162.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:06,956 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 79000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -162.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:11,971 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 80000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -161.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:16,973 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 81000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -161.25\n",
      "Num timesteps: 82000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -161.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:21,983 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 83000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -160.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:26,989 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 84000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -160.03\n",
      "Num timesteps: 85000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -159.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:31,994 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 86000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -159.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:36,999 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 87000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -159.25\n",
      "Num timesteps: 88000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -158.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:42,005 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 89000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -156.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:47,011 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 90000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -155.56\n",
      "Num timesteps: 91000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -155.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:52,014 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 92000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -155.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:38:57,017 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 93000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -154.43\n",
      "Num timesteps: 94000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -154.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:02,025 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 95000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -153.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:07,030 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 96000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -152.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:12,033 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 97000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -151.99\n",
      "Num timesteps: 98000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -152.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:17,038 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 99000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -150.10\n",
      "Num timesteps: 100000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -150.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:22,042 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 101000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -149.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:27,045 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 102000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -147.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:32,048 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 103000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -145.93\n",
      "Num timesteps: 104000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -145.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:37,051 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 105000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -142.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:42,053 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 106000\n",
      "Best mean reward: -138.96 - Last mean reward per episode: -138.77\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 107000\n",
      "Best mean reward: -138.77 - Last mean reward per episode: -136.27\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:47,055 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 108000\n",
      "Best mean reward: -136.27 - Last mean reward per episode: -135.39\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:52,059 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 109000\n",
      "Best mean reward: -135.39 - Last mean reward per episode: -133.44\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 110000\n",
      "Best mean reward: -133.44 - Last mean reward per episode: -129.88\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:39:57,068 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 111000\n",
      "Best mean reward: -129.88 - Last mean reward per episode: -128.79\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 112000\n",
      "Best mean reward: -128.79 - Last mean reward per episode: -126.75\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:02,070 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 113000\n",
      "Best mean reward: -126.75 - Last mean reward per episode: -125.16\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:07,072 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 114000\n",
      "Best mean reward: -125.16 - Last mean reward per episode: -125.76\n",
      "Num timesteps: 115000\n",
      "Best mean reward: -125.16 - Last mean reward per episode: -127.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:12,075 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 116000\n",
      "Best mean reward: -125.16 - Last mean reward per episode: -127.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:17,080 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 117000\n",
      "Best mean reward: -125.16 - Last mean reward per episode: -126.70\n",
      "Num timesteps: 118000\n",
      "Best mean reward: -125.16 - Last mean reward per episode: -125.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:22,082 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 119000\n",
      "Best mean reward: -125.16 - Last mean reward per episode: -126.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:27,088 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 120000\n",
      "Best mean reward: -125.16 - Last mean reward per episode: -124.27\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 121000\n",
      "Best mean reward: -124.27 - Last mean reward per episode: -123.71\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:32,089 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 122000\n",
      "Best mean reward: -123.71 - Last mean reward per episode: -121.08\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:37,091 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 123000\n",
      "Best mean reward: -121.08 - Last mean reward per episode: -121.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:42,096 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 124000\n",
      "Best mean reward: -121.08 - Last mean reward per episode: -120.89\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 125000\n",
      "Best mean reward: -120.89 - Last mean reward per episode: -121.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:47,099 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 126000\n",
      "Best mean reward: -120.89 - Last mean reward per episode: -124.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:52,104 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 127000\n",
      "Best mean reward: -120.89 - Last mean reward per episode: -124.28\n",
      "Num timesteps: 128000\n",
      "Best mean reward: -120.89 - Last mean reward per episode: -122.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:40:57,107 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 129000\n",
      "Best mean reward: -120.89 - Last mean reward per episode: -121.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:02,110 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 130000\n",
      "Best mean reward: -120.89 - Last mean reward per episode: -119.18\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 131000\n",
      "Best mean reward: -119.18 - Last mean reward per episode: -119.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:07,113 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 132000\n",
      "Best mean reward: -119.18 - Last mean reward per episode: -115.10\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:12,120 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 133000\n",
      "Best mean reward: -115.10 - Last mean reward per episode: -113.26\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 134000\n",
      "Best mean reward: -113.26 - Last mean reward per episode: -111.99\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:17,124 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 135000\n",
      "Best mean reward: -111.99 - Last mean reward per episode: -109.77\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:22,133 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 136000\n",
      "Best mean reward: -109.77 - Last mean reward per episode: -107.42\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:27,135 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 137000\n",
      "Best mean reward: -107.42 - Last mean reward per episode: -105.32\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 138000\n",
      "Best mean reward: -105.32 - Last mean reward per episode: -103.48\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:32,147 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 139000\n",
      "Best mean reward: -103.48 - Last mean reward per episode: -100.00\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:37,155 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 140000\n",
      "Best mean reward: -100.00 - Last mean reward per episode: -98.72\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 141000\n",
      "Best mean reward: -98.72 - Last mean reward per episode: -97.06\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:42,156 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 142000\n",
      "Best mean reward: -97.06 - Last mean reward per episode: -95.02\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:47,158 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 143000\n",
      "Best mean reward: -95.02 - Last mean reward per episode: -93.78\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 144000\n",
      "Best mean reward: -93.78 - Last mean reward per episode: -94.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:52,161 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 145000\n",
      "Best mean reward: -93.78 - Last mean reward per episode: -93.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:41:57,163 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 146000\n",
      "Best mean reward: -93.78 - Last mean reward per episode: -93.22\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 147000\n",
      "Best mean reward: -93.22 - Last mean reward per episode: -93.14\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:02,170 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 148000\n",
      "Best mean reward: -93.14 - Last mean reward per episode: -93.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:07,174 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 149000\n",
      "Best mean reward: -93.14 - Last mean reward per episode: -92.86\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 150000\n",
      "Best mean reward: -92.86 - Last mean reward per episode: -93.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:12,176 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 151000\n",
      "Best mean reward: -92.86 - Last mean reward per episode: -92.03\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:17,186 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 152000\n",
      "Best mean reward: -92.03 - Last mean reward per episode: -91.39\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:22,189 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 153000\n",
      "Best mean reward: -91.39 - Last mean reward per episode: -90.99\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:27,196 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 154000\n",
      "Best mean reward: -90.99 - Last mean reward per episode: -89.54\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 155000\n",
      "Best mean reward: -89.54 - Last mean reward per episode: -87.72\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:32,199 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 156000\n",
      "Best mean reward: -87.72 - Last mean reward per episode: -86.36\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:37,204 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 157000\n",
      "Best mean reward: -86.36 - Last mean reward per episode: -84.86\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 158000\n",
      "Best mean reward: -84.86 - Last mean reward per episode: -87.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:42,209 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 159000\n",
      "Best mean reward: -84.86 - Last mean reward per episode: -85.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:47,215 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 160000\n",
      "Best mean reward: -84.86 - Last mean reward per episode: -85.84\n",
      "Num timesteps: 161000\n",
      "Best mean reward: -84.86 - Last mean reward per episode: -84.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:52,219 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 162000\n",
      "Best mean reward: -84.86 - Last mean reward per episode: -84.76\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:42:57,221 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 163000\n",
      "Best mean reward: -84.76 - Last mean reward per episode: -86.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:02,223 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 164000\n",
      "Best mean reward: -84.76 - Last mean reward per episode: -85.75\n",
      "Num timesteps: 165000\n",
      "Best mean reward: -84.76 - Last mean reward per episode: -84.57\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:07,237 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 166000\n",
      "Best mean reward: -84.57 - Last mean reward per episode: -83.40\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:12,239 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 167000\n",
      "Best mean reward: -83.40 - Last mean reward per episode: -82.89\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 168000\n",
      "Best mean reward: -82.89 - Last mean reward per episode: -82.83\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:17,241 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 169000\n",
      "Best mean reward: -82.83 - Last mean reward per episode: -81.87\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:22,247 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 170000\n",
      "Best mean reward: -81.87 - Last mean reward per episode: -80.65\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 171000\n",
      "Best mean reward: -80.65 - Last mean reward per episode: -79.91\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:27,250 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 172000\n",
      "Best mean reward: -79.91 - Last mean reward per episode: -80.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:32,257 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 173000\n",
      "Best mean reward: -79.91 - Last mean reward per episode: -79.43\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:37,258 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 174000\n",
      "Best mean reward: -79.43 - Last mean reward per episode: -77.90\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:42,260 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 175000\n",
      "Best mean reward: -77.90 - Last mean reward per episode: -77.12\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 176000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -77.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:47,267 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 177000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -78.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:52,273 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 178000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -79.38\n",
      "Num timesteps: 179000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -79.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:43:57,278 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 180000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -79.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:02,286 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 181000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -78.41\n",
      "Num timesteps: 182000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -77.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:07,289 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 183000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -79.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:12,291 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 184000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -80.04\n",
      "Num timesteps: 185000\n",
      "Best mean reward: -77.12 - Last mean reward per episode: -77.00\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:17,295 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 186000\n",
      "Best mean reward: -77.00 - Last mean reward per episode: -78.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:22,299 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 187000\n",
      "Best mean reward: -77.00 - Last mean reward per episode: -77.86\n",
      "Num timesteps: 188000\n",
      "Best mean reward: -77.00 - Last mean reward per episode: -77.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:27,305 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 189000\n",
      "Best mean reward: -77.00 - Last mean reward per episode: -76.27\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:32,306 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 190000\n",
      "Best mean reward: -76.27 - Last mean reward per episode: -74.97\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:37,311 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 191000\n",
      "Best mean reward: -74.97 - Last mean reward per episode: -74.81\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:42,317 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 192000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -75.13\n",
      "Num timesteps: 193000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -75.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:47,319 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 194000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -75.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:52,323 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 195000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -75.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:44:57,330 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 196000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -76.35\n",
      "Num timesteps: 197000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -76.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:02,331 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 198000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -76.59\n",
      "Num timesteps: 199000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -74.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:07,333 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 200000\n",
      "Best mean reward: -74.81 - Last mean reward per episode: -72.78\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:12,337 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 201000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -73.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:17,342 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 202000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -74.08\n",
      "Num timesteps: 203000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -73.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:22,345 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 204000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -74.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:27,349 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 205000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -73.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:32,360 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 206000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -74.37\n",
      "Num timesteps: 207000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -74.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:37,365 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 208000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -74.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:42,367 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 209000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -73.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:47,370 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 210000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -74.28\n",
      "Num timesteps: 211000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -74.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:52,371 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 212000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -75.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:45:57,373 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 213000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -75.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:02,375 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 214000\n",
      "Best mean reward: -72.78 - Last mean reward per episode: -72.27\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 215000\n",
      "Best mean reward: -72.27 - Last mean reward per episode: -71.64\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:07,378 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 216000\n",
      "Best mean reward: -71.64 - Last mean reward per episode: -71.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:12,380 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 217000\n",
      "Best mean reward: -71.64 - Last mean reward per episode: -70.73\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:17,385 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 218000\n",
      "Best mean reward: -70.73 - Last mean reward per episode: -70.48\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:22,389 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 219000\n",
      "Best mean reward: -70.48 - Last mean reward per episode: -68.32\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:27,391 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 220000\n",
      "Best mean reward: -68.32 - Last mean reward per episode: -68.03\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 221000\n",
      "Best mean reward: -68.03 - Last mean reward per episode: -67.34\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:32,392 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 222000\n",
      "Best mean reward: -67.34 - Last mean reward per episode: -66.47\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:37,393 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 223000\n",
      "Best mean reward: -66.47 - Last mean reward per episode: -62.70\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:42,395 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 224000\n",
      "Best mean reward: -62.70 - Last mean reward per episode: -61.86\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 225000\n",
      "Best mean reward: -61.86 - Last mean reward per episode: -57.97\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:47,398 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 226000\n",
      "Best mean reward: -57.97 - Last mean reward per episode: -58.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:52,402 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 227000\n",
      "Best mean reward: -57.97 - Last mean reward per episode: -58.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:46:57,405 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 228000\n",
      "Best mean reward: -57.97 - Last mean reward per episode: -58.85\n",
      "Num timesteps: 229000\n",
      "Best mean reward: -57.97 - Last mean reward per episode: -58.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:02,408 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 230000\n",
      "Best mean reward: -57.97 - Last mean reward per episode: -58.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:07,414 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 231000\n",
      "Best mean reward: -57.97 - Last mean reward per episode: -57.84\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:12,418 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 232000\n",
      "Best mean reward: -57.84 - Last mean reward per episode: -57.43\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:17,421 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 233000\n",
      "Best mean reward: -57.43 - Last mean reward per episode: -57.01\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:22,434 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 234000\n",
      "Best mean reward: -57.01 - Last mean reward per episode: -56.79\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 235000\n",
      "Best mean reward: -56.79 - Last mean reward per episode: -56.21\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:27,436 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 236000\n",
      "Best mean reward: -56.21 - Last mean reward per episode: -56.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:32,439 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 237000\n",
      "Best mean reward: -56.21 - Last mean reward per episode: -56.01\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:37,442 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 238000\n",
      "Best mean reward: -56.01 - Last mean reward per episode: -55.51\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 239000\n",
      "Best mean reward: -55.51 - Last mean reward per episode: -54.59\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:42,444 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 240000\n",
      "Best mean reward: -54.59 - Last mean reward per episode: -54.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:47,446 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 241000\n",
      "Best mean reward: -54.59 - Last mean reward per episode: -54.40\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 242000\n",
      "Best mean reward: -54.40 - Last mean reward per episode: -44.78\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:52,448 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 243000\n",
      "Best mean reward: -44.78 - Last mean reward per episode: -41.80\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:47:57,450 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 244000\n",
      "Best mean reward: -41.80 - Last mean reward per episode: -41.54\n",
      "Saving new best model to machine-learning/logs/best_model\n",
      "Num timesteps: 245000\n",
      "Best mean reward: -41.54 - Last mean reward per episode: -37.34\n",
      "Saving new best model to machine-learning/logs/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:48:02,456 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 246000\n",
      "Best mean reward: -37.34 - Last mean reward per episode: -100.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:48:07,458 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 247000\n",
      "Best mean reward: -37.34 - Last mean reward per episode: -97.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:48:12,461 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 248000\n",
      "Best mean reward: -37.34 - Last mean reward per episode: -88.61\n",
      "Num timesteps: 249000\n",
      "Best mean reward: -37.34 - Last mean reward per episode: -91.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:48:17,466 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 250000\n",
      "Best mean reward: -37.34 - Last mean reward per episode: -88.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:48:22,467 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 251000\n",
      "Best mean reward: -37.34 - Last mean reward per episode: -85.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 17:48:27,469 [21055] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 252000\n",
      "Best mean reward: -37.34 - Last mean reward per episode: -76.37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5fbe14e12953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLnMlpPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, replay_wrapper)\u001b[0m\n\u001b[1;32m    892\u001b[0m                                 \u001b[0munscaled_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munscale_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munscaled_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/stable_baselines/bench/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApplyLinearImpulse\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0moy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpulse_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mBeginContact\u001b[0;34m(self, contact)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcontactListener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mBeginContact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcontact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixtureA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcontact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixtureB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Because we use parameter noise, we should use a MlpPolicy with layer normalization\n",
    "model = DDPG(LnMlpPolicy, env, param_noise=param_noise, verbose=False)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(1e6), callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e62603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"machine-learning/models/LunarLander1e4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d894e",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f38ba807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7afb180b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:332: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/policies.py:134: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:459: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:459: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:132: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:412: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:444: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:720: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:432: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/darias/.local/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py:452: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DDPG.load(\"machine-learning/models/LunarLander1e4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82554fc",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f894f4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-123.82219406697347\n",
      "Episode:2 Score:-133.2739114629593\n",
      "Episode:3 Score:-130.24295683601557\n",
      "Episode:4 Score:-139.4435809410889\n",
      "Episode:5 Score:-113.8290322685659\n"
     ]
    }
   ],
   "source": [
    "# Enjoy trained agent\n",
    "episodes = 5\n",
    "for episodes in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episodes, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1601f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c99a05",
   "metadata": {},
   "source": [
    "### Ploting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61026471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines import results_plotter\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results([log_dir], 1e5, results_plotter.X_TIMESTEPS, \"DDPG LunarLander\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26f49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(values, window):\n",
    "    \"\"\"\n",
    "    Smooth values by doing a moving average\n",
    "    :param values: (numpy array)\n",
    "    :param window: (int)\n",
    "    :return: (numpy array)\n",
    "    \"\"\"\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, 'valid')\n",
    "\n",
    "\n",
    "def plot_results(log_folder, title='Learning Curve'):\n",
    "    \"\"\"\n",
    "    plot the results\n",
    "\n",
    "    :param log_folder: (str) the save location of the results to plot\n",
    "    :param title: (str) the title of the task to plot\n",
    "    \"\"\"\n",
    "    x, y = ts2xy(load_results(log_folder), 'timesteps')\n",
    "    y = moving_average(y, window=50)\n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y):]\n",
    "\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Number of Timesteps')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.title(title + \" Smoothed\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f66a8b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a2391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
